{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys, glob, shutil, json\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\nimport cv2\n\nfrom PIL import Image\nimport numpy as np\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SVHNDataset(Dataset):\n    def __init__(self, img_path, img_label, transform=None):\n        self.img_path = img_path\n        self.img_label = img_label \n        if transform is not None:\n            self.transform = transform\n        else:\n            self.transform = None\n\n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index]).convert('RGB')\n\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        # 设置最长的字符长度为5个\n        lbl = np.array(self.img_label[index], dtype=np.int)\n        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n        return img, torch.from_numpy(np.array(lbl[:5])).long()\n\n    def __len__(self):\n        return len(self.img_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomErasing(object):\n    def __init__(self, p=0.5, sl=0.02, sh=0.4, r1=0.3, r2=3):\n        self.p = p\n        self.sl = sl\n        self.sh = sh\n        self.r1 = r1\n        self.r2 = r2\n\n    def __call__(self, img):\n        \n        if np.random.rand() > self.p:\n            return img\n        \n        img = np.array(img)\n        \n        while True:\n            img_h, img_w, img_c = img.shape\n\n            img_area = img_h * img_w\n            mask_area = np.random.uniform(self.sl, self.sh) * img_area\n            mask_aspect_ratio = np.random.uniform(self.r1, self.r2)\n            mask_w = int(np.sqrt(mask_area / mask_aspect_ratio))\n            mask_h = int(np.sqrt(mask_area * mask_aspect_ratio))\n            \n            mask = np.random.rand(mask_h, mask_w, img_c) * 255\n\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n            right = left + mask_w\n            bottom = top + mask_h\n        \n            if right <= img_w and bottom <= img_h:\n                break\n        \n        img[top:bottom, left:right, :] = mask\n        \n        return Image.fromarray(img)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_path = glob.glob('../input/jiejingshibie/train/train/*.png')\ntrain_path.sort()\ntrain_json = json.load(open('../input/jiejingshibie/train.json'))\n\n\n\nval_path = glob.glob('../input/jiejingshibie/val/val/*.png')\nval_path.sort()\nval_json = json.load(open('../input/jiejingshibie/val.json'))\npath = train_path + val_path\ntrain_path = path[8000:]\nval_path = path[:8000]\n\n\ntrain_label = [train_json[x]['label'] for x in train_json]\nval_label = [val_json[x]['label'] for x in val_json]\nlabel = train_label + val_label\ntrain_label = label[8000:]\nval_label = label[:8000]\n\nprint(len(train_path), len(train_label))\nprint(len(val_path), len(val_label))\n\n\ntrain_loader = torch.utils.data.DataLoader(\n    SVHNDataset(train_path, train_label,\n                transforms.Compose([\n                    transforms.Resize((108, 216)),\n                    transforms.RandomCrop((100, 200)),\n                    transforms.ColorJitter(0.3, 0.3, 0.2),\n#                     RandomErasing(p=0.2, sh=0.2),\n                    transforms.RandomGrayscale(p=0.2),\n                    transforms.RandomRotation(5),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])), \n    batch_size=128, \n    shuffle=True, \n    num_workers=16,\n)\n\n\n\nval_loader = torch.utils.data.DataLoader(\n    SVHNDataset(val_path, val_label,\n                transforms.Compose([\n                    transforms.Resize((100, 200)),\n                    # transforms.RandomGrayscale(p=1),\n                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n                    # transforms.RandomRotation(5),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])), \n    batch_size=128, \n    shuffle=False, \n    num_workers=16,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SVHN_Model1(nn.Module):\n    def __init__(self):\n        super(SVHN_Model1, self).__init__()\n                \n        model_conv = models.resnet50(pretrained=True)\n        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n        self.cnn = model_conv\n        self.fc1 = nn.Linear(2048, 11)\n        self.fc2 = nn.Linear(2048, 11)\n        self.fc3 = nn.Linear(2048, 11)\n        self.fc4 = nn.Linear(2048, 11)\n        self.fc5 = nn.Linear(2048, 11)\n#         self.fc6 = nn.Linear(3072, 7)\n#         self.hidden1 = nn.Sequential(\n#             nn.Linear(2048, 3072),\n#             nn.ReLU())\n#         self.hidden2 = nn.Sequential(\n#             nn.Linear(3072, 3072),\n#             nn.ReLU())\n        self.dr1 = nn.Dropout(0.5)\n        self.dr2 = nn.Dropout(0.5)\n        self.dr3 = nn.Dropout(0.5)\n        self.dr4 = nn.Dropout(0.5)\n        self.dr5 = nn.Dropout(0.5)\n#         self.dr6 = nn.Dropout(0.5)\n    def forward(self, img):        \n        feat = self.cnn(img)\n        # print(feat.shape)\n        feat = feat.view(feat.shape[0], -1)\n        c1 = self.dr1(self.fc1(feat))\n        c2 = self.dr2(self.fc2(feat))\n        c3 = self.dr3(self.fc3(feat))\n        c4 = self.dr4(self.fc4(feat))\n        c5 = self.dr5(self.fc5(feat))\n\n        return c1, c2, c3, c4, c5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer):\n    # 切换模型为训练模式\n    model.train()\n    train_loss = []\n    \n    for i, (input, target) in enumerate(train_loader):\n        if use_cuda:\n            input = input.cuda()\n            target = target.cuda()\n            \n        c0, c1, c2, c3, c4 = model(input)\n        loss = criterion(c0, target[:, 0])*1.2 + \\\n               criterion(c1, target[:, 1])*1.2 + \\\n               criterion(c2, target[:, 2])*1.1 + \\\n               criterion(c3, target[:, 3])*1.1 + \\\n               criterion(c4, target[:, 4])\n        \n        # loss /= 6\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if i % 100 == 0:\n            print(loss.item())\n        \n        train_loss.append(loss.item())\n    return np.mean(train_loss)\n\ndef validate(val_loader, model, criterion):\n    # 切换模型为预测模型\n    model.eval()\n    val_loss = []\n\n    # 不记录模型梯度信息\n    with torch.no_grad():\n        for i, (input, target) in enumerate(val_loader):\n            if use_cuda:\n                input = input.cuda()\n                target = target.cuda()\n            \n            c0, c1, c2, c3, c4 = model(input)\n            loss = criterion(c0, target[:, 0])*1.2 + \\\n                    criterion(c1, target[:, 1])*1.2 + \\\n                    criterion(c2, target[:, 2])*1.1 + \\\n                    criterion(c3, target[:, 3])*1.1 + \\\n                    criterion(c4, target[:, 4])\n            # loss /= 6\n            val_loss.append(loss.item())\n    return np.mean(val_loss)\n\ndef predict(test_loader, model, tta=10):\n    model.eval()\n    test_pred_tta = None\n    \n    # TTA 次数\n    for _ in range(tta):\n        test_pred = []\n    \n        with torch.no_grad():\n            for i, (input, target) in enumerate(test_loader):\n                if use_cuda:\n                    input = input.cuda()\n                \n                c0, c1, c2, c3, c4 = model(input)\n                output = np.concatenate([\n                    c0.cpu().data.numpy(), \n                    c1.cpu().data.numpy(),\n                    c2.cpu().data.numpy(), \n                    c3.cpu().data.numpy(),\n                    c4.cpu().data.numpy()], axis=1)\n                test_pred.append(output)\n        \n        test_pred = np.vstack(test_pred)\n        if test_pred_tta is None:\n            test_pred_tta = test_pred\n        else:\n            test_pred_tta += test_pred\n    \n    return test_pred_tta","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model = SVHN_Model1()\ncriterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), 0.001)\nbest_loss = 1000.0\n\nuse_cuda = False\nif use_cuda:\n    model = model.cuda()\n\nfor epoch in range(30):\n    if epoch <= 19:\n        lr = 0.001\n    else:\n        lr = 0.0001\n#     optimizer = torch.optim.RMSprop(model.parameters(), lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n    optimizer = torch.optim.Adam(model.parameters(), lr)\n    train_loss = train(train_loader, model, criterion, optimizer)\n    val_loss = validate(val_loader, model, criterion)\n    \n    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n    val_predict_label = predict(val_loader, model, 1)\n    val_predict_label = np.vstack([\n        val_predict_label[:, :11].argmax(1),\n        val_predict_label[:, 11:22].argmax(1),\n        val_predict_label[:, 22:33].argmax(1),\n        val_predict_label[:, 33:44].argmax(1),\n        val_predict_label[:, 44:55].argmax(1),\n    ]).T\n    val_label_pred = []\n    for x in val_predict_label:\n        val_label_pred.append(''.join(map(str, x[x!=10])))\n    \n    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n    \n    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n    print(val_char_acc)\n    # 记录下验证集精度\n    if val_loss < best_loss:\n        best_loss = val_loss\n        torch.save(model.state_dict(), './model1.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(\"model1.pt\"))\n\ntest_path = glob.glob('../input/jiejingshibie/test_a/test_a/*.png')\ntest_path.sort()\ntest_label = [[1]] * len(test_path)\nprint(len(test_path), len(test_label))\n\ntest_loader = torch.utils.data.DataLoader(\n    SVHNDataset(test_path, test_label,\n                transforms.Compose([\n                    transforms.Resize((100, 200)),\n                    transforms.RandomGrayscale(p=1),\n                    transforms.ColorJitter(0.3, 0.3, 0.2),\n                    transforms.RandomRotation(5),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])), \n    batch_size=40, \n    shuffle=False, \n#     num_workers=10,\n)\n\ntest_predict_label = predict(test_loader, model, 1)\n\ntest_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\ntest_predict_label = np.vstack([\n    test_predict_label[:, :11].argmax(1),\n    test_predict_label[:, 11:22].argmax(1),\n    test_predict_label[:, 22:33].argmax(1),\n    test_predict_label[:, 33:44].argmax(1),\n    test_predict_label[:, 44:55].argmax(1),\n]).T\n\ntest_label_pred = []\nfor x in test_predict_label:\n    test_label_pred.append(''.join(map(str, x[x!=10])))\n    \nimport pandas as pd\ndf_submit = pd.read_csv('../input/jiejing-bianma-shibie/mchar_sample_submit_A.csv')\ndf_submit['file_code'] = test_label_pred\ndf_submit.to_csv('renset50tta.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(\"model1.pt\"))\n\ntest_path = glob.glob('../input/jiejingshibie/test_a/test_a/*.png')\ntest_path.sort()\ntest_label = [[1]] * len(test_path)\nprint(len(test_path), len(test_label))\n\ntest_loader = torch.utils.data.DataLoader(\n    SVHNDataset(test_path, test_label,\n                transforms.Compose([\n                    transforms.Resize((100, 200)),\n#                     transforms.RandomGrayscale(p=1),\n#                     transforms.ColorJitter(0.3, 0.3, 0.2),\n#                     transforms.RandomRotation(5),\n                    transforms.ToTensor(),\n                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])), \n    batch_size=40, \n    shuffle=False, \n#     num_workers=10,\n)\n\ntest_predict_label = predict(test_loader, model, 1)\n\ntest_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\ntest_predict_label = np.vstack([\n    test_predict_label[:, :11].argmax(1),\n    test_predict_label[:, 11:22].argmax(1),\n    test_predict_label[:, 22:33].argmax(1),\n    test_predict_label[:, 33:44].argmax(1),\n    test_predict_label[:, 44:55].argmax(1),\n]).T\n\ntest_label_pred = []\nfor x in test_predict_label:\n    test_label_pred.append(''.join(map(str, x[x!=10])))\n    \nimport pandas as pd\ndf_submit = pd.read_csv('../input/jiejing-bianma-shibie/mchar_sample_submit_A.csv')\ndf_submit['file_code'] = test_label_pred\ndf_submit.to_csv('renset50notta.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}